import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset
from torchvision.datasets import CIFAR100
from transformers import ViTForImageClassification, ViTImageProcessor
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict
import os

# --- é…ç½®å‚æ•° ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

MODEL_ID = "google/vit-base-patch16-224"
DATA_DIR = "./data"
SAVE_DIR = "./saved_models"
TARGET_SUPERCLASS = "vehicles_1"  # é€‰æ‹©ç›®æ ‡è¶…ç±»
NUM_EPOCHS = 3  # å¢åŠ è®­ç»ƒè½®æ¬¡ä»¥çœ‹åˆ°æ›´æ˜æ˜¾çš„æ•ˆæœ
BATCH_SIZE = 32
LEARNING_RATE = 2e-5

# åˆ›å»ºä¿å­˜ç›®å½•
os.makedirs(SAVE_DIR, exist_ok=True)

print(f"ğŸ¯ å®éªŒè®¾ç½®ï¼šåªä½¿ç”¨è¶…ç±» '{TARGET_SUPERCLASS}' çš„æ•°æ®è¿›è¡Œå¾®è°ƒ")
print(f"ğŸ“Š è¿™æ¨¡æ‹Ÿäº†è”é‚¦å­¦ä¹ ä¸­ betaâ†’0 çš„æç«¯æ•°æ®åæ–œæƒ…å†µ")

# --- 1. æ•°æ®å‡†å¤‡ ---
processor = ViTImageProcessor.from_pretrained(MODEL_ID)

def transform(examples):
    inputs = processor(images=examples, return_tensors="pt")
    return inputs['pixel_values']

# åŠ è½½å®Œæ•´æ•°æ®é›†
train_dataset = CIFAR100(root=DATA_DIR, train=True, download=True)
test_dataset = CIFAR100(root=DATA_DIR, train=False, download=True)

# CIFAR-100 è¶…ç±»å®šä¹‰
superclass_mapping = {
    "aquatic_mammals": [4, 30, 55, 72, 95],  # beaver, dolphin, otter, seal, whale
    "fish": [1, 32, 67, 73, 91],  # aquarium_fish, flatfish, ray, shark, trout
    "flowers": [54, 62, 70, 82, 92],  # orchid, poppy, rose, sunflower, tulip
    "food_containers": [9, 10, 16, 28, 61],  # bottle, bowl, can, cup, plate
    "fruit_and_vegetables": [0, 51, 53, 57, 83],  # apple, mushroom, orange, pear, sweet_pepper
    "household_electrical_devices": [22, 39, 40, 86, 87],  # clock, keyboard, lamp, telephone, television
    "household_furniture": [5, 20, 25, 84, 94],  # bed, chair, couch, table, wardrobe
    "insects": [6, 7, 14, 18, 24],  # bee, beetle, butterfly, caterpillar, cockroach
    "large_carnivores": [3, 42, 43, 88, 97],  # bear, leopard, lion, tiger, wolf
    "large_man_made_outdoor_things": [12, 17, 37, 68, 76],  # bridge, castle, house, road, skyscraper
    "large_natural_outdoor_scenes": [23, 33, 49, 60, 71],  # cloud, forest, mountain, plain, sea
    "large_omnivores_and_herbivores": [15, 19, 21, 31, 38],  # camel, cattle, chimpanzee, elephant, kangaroo
    "medium_mammals": [34, 63, 64, 66, 75],  # fox, porcupine, possum, raccoon, skunk
    "non_insect_invertebrates": [26, 45, 77, 79, 99],  # crab, lobster, snail, spider, worm
    "people": [2, 11, 35, 46, 98],  # baby, boy, girl, man, woman
    "reptiles": [27, 29, 44, 78, 93],  # crocodile, dinosaur, lizard, snake, turtle
    "small_mammals": [36, 50, 65, 74, 80],  # hamster, mouse, rabbit, shrew, squirrel
    "trees": [47, 52, 56, 59, 96],  # maple_tree, oak_tree, palm_tree, pine_tree, willow_tree
    "vehicles_1": [8, 13, 48, 58, 90],  # bicycle, bus, motorcycle, pickup_truck, train
    "vehicles_2": [41, 69, 81, 85, 89]  # lawn_mower, rocket, streetcar, tank, tractor
}

# CIFAR-100ç±»åˆ«åç§°
class_names = [
    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',
    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',
    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',
    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',
    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',
    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',
    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',
    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',
    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',
    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',
    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',
    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',
    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',
    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',
    'worm'
]

# è·å–ç›®æ ‡è¶…ç±»çš„æ‰€æœ‰ç±»åˆ«
target_classes = superclass_mapping[TARGET_SUPERCLASS]
target_class_names = [class_names[i] for i in target_classes]

print(f"ğŸ·ï¸  ç›®æ ‡è¶…ç±»: {TARGET_SUPERCLASS}")
print(f"ğŸ“ åŒ…å«ç±»åˆ«: {', '.join(target_class_names)}")
print(f"ğŸ”¢ ç±»åˆ«ç´¢å¼•: {target_classes}")

# åˆ›å»ºåªåŒ…å«ç›®æ ‡è¶…ç±»çš„è®­ç»ƒé›†
target_indices = [i for i, (_, label) in enumerate(train_dataset) if label in target_classes]  # type: ignore
target_train_dataset = Subset(train_dataset, target_indices)

print(f"ğŸ“ˆ åŸå§‹è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
print(f"ğŸ¯ ç›®æ ‡è¶…ç±»è®­ç»ƒæ ·æœ¬æ•°: {len(target_train_dataset)}")
print(f"ğŸ“Š å æ€»æ•°æ®çš„æ¯”ä¾‹: {len(target_train_dataset)/len(train_dataset)*100:.1f}%")

class TransformedCifar100(torch.utils.data.Dataset):
    def __init__(self, dataset):
        self.dataset = dataset

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        if isinstance(self.dataset, Subset):
            image, label = self.dataset.dataset[self.dataset.indices[idx]]
        else:
            image, label = self.dataset[idx]
        pixel_values = transform(image).squeeze(0)
        return {"pixel_values": pixel_values, "labels": torch.tensor(label)}

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
target_train_ds = TransformedCifar100(target_train_dataset)
full_test_ds = TransformedCifar100(test_dataset)

target_train_loader = DataLoader(target_train_ds, batch_size=BATCH_SIZE, shuffle=True)
full_test_loader = DataLoader(full_test_ds, batch_size=BATCH_SIZE, shuffle=False)

# --- 2. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¹¶è¯„ä¼°åŸºçº¿æ€§èƒ½ ---
print("\nğŸ”„ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
model = ViTForImageClassification.from_pretrained(
    MODEL_ID,
    num_labels=100,
    ignore_mismatched_sizes=True
).to(device)    

# è¯„ä¼°åŸºçº¿æ€§èƒ½
def evaluate_model_detailed(model, test_loader, target_classes):
    model.eval()
    all_predictions = []
    all_labels = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="è¯„ä¼°ä¸­"):
            pixel_values = batch['pixel_values'].to(device)
            labels = batch['labels'].to(device)
            
            outputs = model(pixel_values=pixel_values)
            predictions = torch.argmax(outputs.logits, dim=-1)
            
            all_predictions.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    all_predictions = np.array(all_predictions)
    all_labels = np.array(all_labels)
    
    # è®¡ç®—æ•´ä½“å‡†ç¡®ç‡
    overall_accuracy = (all_predictions == all_labels).mean()
    
    # è®¡ç®—ç›®æ ‡è¶…ç±»çš„æ€§èƒ½
    target_mask = np.isin(all_labels, target_classes)
    target_accuracy = (all_predictions[target_mask] == all_labels[target_mask]).mean() if target_mask.sum() > 0 else 0
    
    # è®¡ç®—éç›®æ ‡è¶…ç±»çš„æ€§èƒ½
    non_target_mask = ~np.isin(all_labels, target_classes)
    non_target_accuracy = (all_predictions[non_target_mask] == all_labels[non_target_mask]).mean() if non_target_mask.sum() > 0 else 0
    
    # è®¡ç®—ç›®æ ‡è¶…ç±»çš„å¬å›ç‡å’Œç²¾ç¡®ç‡
    target_predicted_mask = np.isin(all_predictions, target_classes)
    precision = (np.isin(all_labels[target_predicted_mask], target_classes)).mean() if target_predicted_mask.sum() > 0 else 0
    recall = target_accuracy  # å¬å›ç‡å°±æ˜¯ç›®æ ‡è¶…ç±»çš„å‡†ç¡®ç‡
    
    # è®¡ç®—æ¯ä¸ªç›®æ ‡ç±»åˆ«çš„è¯¦ç»†æ€§èƒ½
    target_class_accuracies = {}
    for cls in target_classes:
        cls_mask = all_labels == cls
        if cls_mask.sum() > 0:
            cls_accuracy = (all_predictions[cls_mask] == all_labels[cls_mask]).mean()
            target_class_accuracies[cls] = cls_accuracy
        else:
            target_class_accuracies[cls] = 0.0
    
    return {
        'overall_accuracy': overall_accuracy,
        'target_accuracy': target_accuracy,
        'non_target_accuracy': non_target_accuracy,
        'target_precision': precision,
        'target_recall': recall,
        'target_samples': target_mask.sum(),
        'non_target_samples': non_target_mask.sum(),
        'target_class_accuracies': target_class_accuracies
    }

print("ğŸ“Š è¯„ä¼°é¢„è®­ç»ƒæ¨¡å‹çš„åŸºçº¿æ€§èƒ½...")
baseline_results = evaluate_model_detailed(model, full_test_loader, target_classes)

print(f"\nğŸ” åŸºçº¿æ€§èƒ½ (é¢„è®­ç»ƒæ¨¡å‹):")
print(f"   æ•´ä½“å‡†ç¡®ç‡: {baseline_results['overall_accuracy']:.4f}")
print(f"   ç›®æ ‡è¶…ç±» ({TARGET_SUPERCLASS}) å‡†ç¡®ç‡: {baseline_results['target_accuracy']:.4f}")
print(f"   éç›®æ ‡è¶…ç±»å¹³å‡å‡†ç¡®ç‡: {baseline_results['non_target_accuracy']:.4f}")
print(f"   ç›®æ ‡è¶…ç±»ç²¾ç¡®ç‡: {baseline_results['target_precision']:.4f}")
print(f"   ç›®æ ‡è¶…ç±»å¬å›ç‡: {baseline_results['target_recall']:.4f}")
print(f"\nğŸ“‹ å„ä¸ªç±»åˆ«è¯¦ç»†å‡†ç¡®ç‡:")
for cls_idx in target_classes:
    cls_name = class_names[cls_idx]
    cls_acc = baseline_results['target_class_accuracies'][cls_idx]
    print(f"   {cls_name}: {cls_acc:.4f}")

# --- 3. æç«¯åæ–œå¾®è°ƒ ---
print(f"\nğŸš€ å¼€å§‹æç«¯åæ–œå¾®è°ƒ (åªä½¿ç”¨ {TARGET_SUPERCLASS} è¶…ç±»æ•°æ®)...")

optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)

training_losses = []

for epoch in range(NUM_EPOCHS):
    model.train()
    total_loss = 0
    progress_bar = tqdm(target_train_loader, desc=f"Epoch {epoch + 1}/{NUM_EPOCHS}")
    
    for batch in progress_bar:
        optimizer.zero_grad()
        
        pixel_values = batch['pixel_values'].to(device)
        labels = batch['labels'].to(device)
        
        outputs = model(pixel_values=pixel_values, labels=labels)
        loss = outputs.loss
        total_loss += loss.item()
        
        loss.backward()
        optimizer.step()
        
        progress_bar.set_postfix({'loss': loss.item()})
    
    avg_loss = total_loss / len(target_train_loader)
    training_losses.append(avg_loss)
    print(f"Epoch {epoch + 1} å¹³å‡æŸå¤±: {avg_loss:.4f}")

# --- 4. è¯„ä¼°å¾®è°ƒåæ€§èƒ½ ---
print("\nğŸ“Š è¯„ä¼°å¾®è°ƒåæ¨¡å‹æ€§èƒ½...")
finetuned_results = evaluate_model_detailed(model, full_test_loader, target_classes)

print(f"\nğŸ¯ å¾®è°ƒåæ€§èƒ½:")
print(f"   æ•´ä½“å‡†ç¡®ç‡: {finetuned_results['overall_accuracy']:.4f}")
print(f"   ç›®æ ‡è¶…ç±» ({TARGET_SUPERCLASS}) å‡†ç¡®ç‡: {finetuned_results['target_accuracy']:.4f}")
print(f"   éç›®æ ‡è¶…ç±»å¹³å‡å‡†ç¡®ç‡: {finetuned_results['non_target_accuracy']:.4f}")
print(f"   ç›®æ ‡è¶…ç±»ç²¾ç¡®ç‡: {finetuned_results['target_precision']:.4f}")
print(f"   ç›®æ ‡è¶…ç±»å¬å›ç‡: {finetuned_results['target_recall']:.4f}")
print(f"\nğŸ“‹ å„ä¸ªç±»åˆ«è¯¦ç»†å‡†ç¡®ç‡:")
for cls_idx in target_classes:
    cls_name = class_names[cls_idx]
    cls_acc = finetuned_results['target_class_accuracies'][cls_idx]
    print(f"   {cls_name}: {cls_acc:.4f}")

# --- 5. æ€§èƒ½å¯¹æ¯”åˆ†æ ---
print(f"\nğŸ“ˆ æ€§èƒ½å˜åŒ–åˆ†æ:")
overall_change = finetuned_results['overall_accuracy'] - baseline_results['overall_accuracy']
target_change = finetuned_results['target_accuracy'] - baseline_results['target_accuracy']
non_target_change = finetuned_results['non_target_accuracy'] - baseline_results['non_target_accuracy']

print(f"   æ•´ä½“å‡†ç¡®ç‡å˜åŒ–: {overall_change:+.4f}")
print(f"   ç›®æ ‡è¶…ç±»å‡†ç¡®ç‡å˜åŒ–: {target_change:+.4f}")
print(f"   éç›®æ ‡è¶…ç±»å‡†ç¡®ç‡å˜åŒ–: {non_target_change:+.4f}")

if target_change > 0:
    print(f"   âœ… ç›®æ ‡è¶…ç±»æ€§èƒ½æå‡äº† {target_change:.4f}")
else:
    print(f"   âŒ ç›®æ ‡è¶…ç±»æ€§èƒ½ä¸‹é™äº† {abs(target_change):.4f}")

if non_target_change > 0:
    print(f"   âœ… éç›®æ ‡è¶…ç±»æ€§èƒ½æå‡äº† {non_target_change:.4f}")
else:
    print(f"   âŒ éç›®æ ‡è¶…ç±»æ€§èƒ½ä¸‹é™äº† {abs(non_target_change):.4f}")

# åˆ†æå„ä¸ªç±»åˆ«çš„å˜åŒ–
print(f"\nğŸ“Š ç›®æ ‡è¶…ç±»å†…å„ç±»åˆ«æ€§èƒ½å˜åŒ–:")
for cls_idx in target_classes:
    cls_name = class_names[cls_idx]
    baseline_cls_acc = baseline_results['target_class_accuracies'][cls_idx]
    finetuned_cls_acc = finetuned_results['target_class_accuracies'][cls_idx]
    cls_change = finetuned_cls_acc - baseline_cls_acc
    print(f"   {cls_name}: {baseline_cls_acc:.4f} â†’ {finetuned_cls_acc:.4f} ({cls_change:+.4f})")

# --- 6. å¯è§†åŒ–ç»“æœ ---
plt.figure(figsize=(15, 10))

# å­å›¾1: è®­ç»ƒæŸå¤±
plt.subplot(2, 3, 1)
plt.plot(training_losses, 'b-', linewidth=2)
plt.title('è®­ç»ƒæŸå¤±æ›²çº¿')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True, alpha=0.3)

# å­å›¾2: å‡†ç¡®ç‡å¯¹æ¯”
plt.subplot(2, 3, 2)
categories = ['æ•´ä½“', 'ç›®æ ‡è¶…ç±»', 'éç›®æ ‡è¶…ç±»']
baseline_values = [baseline_results['overall_accuracy'], 
                  baseline_results['target_accuracy'], 
                  baseline_results['non_target_accuracy']]
finetuned_values = [finetuned_results['overall_accuracy'], 
                   finetuned_results['target_accuracy'], 
                   finetuned_results['non_target_accuracy']]

x = np.arange(len(categories))
width = 0.35

plt.bar(x - width/2, baseline_values, width, label='åŸºçº¿æ¨¡å‹', alpha=0.8)
plt.bar(x + width/2, finetuned_values, width, label='å¾®è°ƒåæ¨¡å‹', alpha=0.8)

plt.xlabel('ç±»åˆ«')
plt.ylabel('å‡†ç¡®ç‡')
plt.title('æ€§èƒ½å¯¹æ¯”')
plt.xticks(x, categories)
plt.legend()
plt.grid(True, alpha=0.3)

# å­å›¾3: å˜åŒ–å¹…åº¦
plt.subplot(2, 3, 3)
changes = [overall_change, target_change, non_target_change]
colors = ['green' if x >= 0 else 'red' for x in changes]
plt.bar(categories, changes, color=colors, alpha=0.7)
plt.xlabel('ç±»åˆ«')
plt.ylabel('å‡†ç¡®ç‡å˜åŒ–')
plt.title('æ€§èƒ½å˜åŒ– (å¾®è°ƒå - åŸºçº¿)')
plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)
plt.grid(True, alpha=0.3)

# å­å›¾4: ç›®æ ‡è¶…ç±»è¯¦ç»†åˆ†æ
plt.subplot(2, 3, 4)
target_metrics = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡']
baseline_target = [baseline_results['target_accuracy'], 
                  baseline_results['target_precision'], 
                  baseline_results['target_recall']]
finetuned_target = [finetuned_results['target_accuracy'], 
                   finetuned_results['target_precision'], 
                   finetuned_results['target_recall']]

x_metrics = np.arange(len(target_metrics))
plt.bar(x_metrics - width/2, baseline_target, width, label='åŸºçº¿æ¨¡å‹', alpha=0.8)
plt.bar(x_metrics + width/2, finetuned_target, width, label='å¾®è°ƒåæ¨¡å‹', alpha=0.8)

plt.xlabel('æŒ‡æ ‡')
plt.ylabel('åˆ†æ•°')
plt.title(f'ç›®æ ‡è¶…ç±» ({TARGET_SUPERCLASS}) è¯¦ç»†åˆ†æ')
plt.xticks(x_metrics, target_metrics)
plt.legend()
plt.grid(True, alpha=0.3)

# å­å›¾5: æ•°æ®åˆ†å¸ƒå¯è§†åŒ–
plt.subplot(2, 3, 5)
labels = [f'ç›®æ ‡è¶…ç±»\n({TARGET_SUPERCLASS})', 'å…¶ä»–19ä¸ªè¶…ç±»']
sizes = [len(target_train_dataset), len(train_dataset) - len(target_train_dataset)]
colors = ['#ff9999', '#66b3ff']
plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
plt.title('è®­ç»ƒæ•°æ®åˆ†å¸ƒ\n(æ¨¡æ‹Ÿ betaâ†’0 çš„æç«¯åæ–œ)')

# å­å›¾6: æ€§èƒ½æ€»ç»“
plt.subplot(2, 3, 6)
plt.text(0.1, 0.9, f"ğŸ¯ å®éªŒæ€»ç»“", fontsize=14, fontweight='bold', transform=plt.gca().transAxes)
plt.text(0.1, 0.8, f"ç›®æ ‡è¶…ç±»: {TARGET_SUPERCLASS}", fontsize=12, transform=plt.gca().transAxes)
plt.text(0.1, 0.7, f"è®­ç»ƒæ ·æœ¬: {len(target_train_dataset)}", fontsize=12, transform=plt.gca().transAxes)
plt.text(0.1, 0.6, f"æ•´ä½“æ€§èƒ½å˜åŒ–: {overall_change:+.4f}", fontsize=12, transform=plt.gca().transAxes)
plt.text(0.1, 0.5, f"ç›®æ ‡è¶…ç±»æ€§èƒ½å˜åŒ–: {target_change:+.4f}", fontsize=12, transform=plt.gca().transAxes)
plt.text(0.1, 0.4, f"éç›®æ ‡è¶…ç±»æ€§èƒ½å˜åŒ–: {non_target_change:+.4f}", fontsize=12, transform=plt.gca().transAxes)

catastrophic_forgetting = abs(non_target_change) > 0.1
if catastrophic_forgetting:
    plt.text(0.1, 0.3, "âš ï¸  æ£€æµ‹åˆ°ç¾éš¾æ€§é—å¿˜", fontsize=12, color='red', transform=plt.gca().transAxes)
else:
    plt.text(0.1, 0.3, "âœ… æœªå‘ç”Ÿä¸¥é‡é—å¿˜", fontsize=12, color='green', transform=plt.gca().transAxes)

plt.axis('off')

plt.tight_layout()
plt.savefig(f'{SAVE_DIR}/extreme_bias_analysis_superclass_{TARGET_SUPERCLASS}.png', dpi=300, bbox_inches='tight')
plt.show()

# --- 7. ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹ ---
model_save_path = f"{SAVE_DIR}/vit_extreme_bias_superclass_{TARGET_SUPERCLASS}"
print(f"\nğŸ’¾ ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹åˆ°: {model_save_path}")

model.save_pretrained(model_save_path)
processor.save_pretrained(model_save_path)

# ä¿å­˜å®éªŒç»“æœ
results_save_path = f"{SAVE_DIR}/extreme_bias_results_superclass_{TARGET_SUPERCLASS}.txt"
with open(results_save_path, 'w', encoding='utf-8') as f:
    f.write(f"æç«¯æ•°æ®åæ–œå®éªŒç»“æœ (betaâ†’0)\n")
    f.write(f"==================================\n\n")
    f.write(f"å®éªŒè®¾ç½®:\n")
    f.write(f"  ç›®æ ‡è¶…ç±»: {TARGET_SUPERCLASS}\n")
    f.write(f"  åŒ…å«ç±»åˆ«: {', '.join(target_class_names)}\n")
    f.write(f"  è®­ç»ƒæ ·æœ¬æ•°: {len(target_train_dataset)}\n")
    f.write(f"  è®­ç»ƒè½®æ¬¡: {NUM_EPOCHS}\n")
    f.write(f"  å­¦ä¹ ç‡: {LEARNING_RATE}\n\n")
    
    f.write(f"åŸºçº¿æ€§èƒ½ (é¢„è®­ç»ƒæ¨¡å‹):\n")
    f.write(f"  æ•´ä½“å‡†ç¡®ç‡: {baseline_results['overall_accuracy']:.4f}\n")
    f.write(f"  ç›®æ ‡è¶…ç±»å‡†ç¡®ç‡: {baseline_results['target_accuracy']:.4f}\n")
    f.write(f"  éç›®æ ‡è¶…ç±»å‡†ç¡®ç‡: {baseline_results['non_target_accuracy']:.4f}\n")
    for cls_idx in target_classes:
        cls_name = class_names[cls_idx]
        cls_acc = baseline_results['target_class_accuracies'][cls_idx]
        f.write(f"    {cls_name}: {cls_acc:.4f}\n")
    f.write(f"\n")
    
    f.write(f"å¾®è°ƒåæ€§èƒ½:\n")
    f.write(f"  æ•´ä½“å‡†ç¡®ç‡: {finetuned_results['overall_accuracy']:.4f}\n")
    f.write(f"  ç›®æ ‡è¶…ç±»å‡†ç¡®ç‡: {finetuned_results['target_accuracy']:.4f}\n")
    f.write(f"  éç›®æ ‡è¶…ç±»å‡†ç¡®ç‡: {finetuned_results['non_target_accuracy']:.4f}\n")
    for cls_idx in target_classes:
        cls_name = class_names[cls_idx]
        cls_acc = finetuned_results['target_class_accuracies'][cls_idx]
        f.write(f"    {cls_name}: {cls_acc:.4f}\n")
    f.write(f"\n")
    
    f.write(f"æ€§èƒ½å˜åŒ–:\n")
    f.write(f"  æ•´ä½“å‡†ç¡®ç‡å˜åŒ–: {overall_change:+.4f}\n")
    f.write(f"  ç›®æ ‡è¶…ç±»å‡†ç¡®ç‡å˜åŒ–: {target_change:+.4f}\n")
    f.write(f"  éç›®æ ‡è¶…ç±»å‡†ç¡®ç‡å˜åŒ–: {non_target_change:+.4f}\n")
    f.write(f"  è¶…ç±»å†…å„ç±»åˆ«å˜åŒ–:\n")
    for cls_idx in target_classes:
        cls_name = class_names[cls_idx]
        baseline_cls_acc = baseline_results['target_class_accuracies'][cls_idx]
        finetuned_cls_acc = finetuned_results['target_class_accuracies'][cls_idx]
        cls_change = finetuned_cls_acc - baseline_cls_acc
        f.write(f"    {cls_name}: {cls_change:+.4f}\n")
    f.write(f"\n")
    
    if abs(non_target_change) > 0.1:
        f.write(f"âš ï¸  æ£€æµ‹åˆ°ä¸¥é‡çš„ç¾éš¾æ€§é—å¿˜ç°è±¡\n")
    else:
        f.write(f"âœ… æœªå‘ç”Ÿä¸¥é‡çš„ç¾éš¾æ€§é—å¿˜\n")

print(f"ğŸ“„ å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_save_path}")
print(f"\nğŸ‰ å®éªŒå®Œæˆï¼æ‚¨å¯ä»¥åœ¨ {SAVE_DIR} ç›®å½•ä¸­æ‰¾åˆ°:")
print(f"   - å¾®è°ƒåçš„æ¨¡å‹")
print(f"   - æ€§èƒ½åˆ†æå›¾è¡¨")
print(f"   - è¯¦ç»†ç»“æœæŠ¥å‘Š")

print(f"\nğŸ”¬ å…³é”®å‘ç°:")
if target_change > 0.1:
    print(f"   âœ… ç›®æ ‡è¶…ç±»æ€§èƒ½æ˜¾è‘—æå‡ (+{target_change:.4f})")
if abs(non_target_change) > 0.1:
    print(f"   âš ï¸  éç›®æ ‡è¶…ç±»å‡ºç°æ˜æ˜¾æ€§èƒ½ä¸‹é™ ({non_target_change:+.4f}) - è¿™æ˜¯ç¾éš¾æ€§é—å¿˜çš„å…¸å‹è¡¨ç°")
if overall_change < 0:
    print(f"   ğŸ“‰ æ•´ä½“æ€§èƒ½ä¸‹é™ ({overall_change:+.4f}) - è¯´æ˜æç«¯åæ–œçš„è´Ÿé¢å½±å“")

print(f"\nğŸ’¡ è¿™ä¸ªå®éªŒæ¨¡æ‹Ÿäº†è”é‚¦å­¦ä¹ ä¸­å®¢æˆ·ç«¯æ•°æ®æåº¦ä¸å¹³è¡¡çš„æƒ…å†µï¼Œ")
print(f"   æœ‰åŠ©äºç†è§£æ•°æ®å¼‚æ„æ€§å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚")
